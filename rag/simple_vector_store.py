# rag/simple_vector_store.py
"""
Simple Vector Store s·ª≠ d·ª•ng TF-IDF
KH√îNG c·∫ßn download model t·ª´ HuggingFace
Ho·∫°t ƒë·ªông ho√†n to√†n OFFLINE
"""
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


class SimpleVectorStore:
    """Vector store ƒë∆°n gi·∫£n d√πng TF-IDF thay v√¨ neural embeddings"""

    def __init__(self, model_name: str = None):
        # model_name kh√¥ng d√πng, ch·ªâ gi·ªØ ƒë·ªÉ t∆∞∆°ng th√≠ch interface
        self.vectorizer = TfidfVectorizer(
            max_features=5000,  # Gi·ªõi h·∫°n s·ªë features
            ngram_range=(1, 2),  # Unigrams v√† bigrams
            min_df=1,  # T·∫ßn su·∫•t t·ªëi thi·ªÉu
            sublinear_tf=True  # Scale logarithmic
        )
        self.vectors = None
        self.texts = []

    def build(self, texts: list[str]):
        """Build TF-IDF vectors t·ª´ danh s√°ch texts"""
        print("üîé ƒêang t·∫°o TF-IDF vectors (OFFLINE mode)...")

        self.texts = texts
        # Fit v√† transform texts th√†nh TF-IDF vectors
        self.vectors = self.vectorizer.fit_transform(texts)

        print(f"‚úÖ TF-IDF index: {len(texts)} documents, {self.vectors.shape[1]} features")

    def search(self, query: str, k: int = 3) -> list[str]:
        """T√¨m ki·∫øm top-k documents gi·ªëng nh·∫•t v·ªõi query"""
        if self.vectors is None:
            return []

        # Transform query th√†nh TF-IDF vector
        query_vector = self.vectorizer.transform([query])

        # T√≠nh cosine similarity
        similarities = cosine_similarity(query_vector, self.vectors)[0]

        # L·∫•y top-k indices
        top_indices = np.argsort(similarities)[-k:][::-1]

        # Tr·∫£ v·ªÅ texts t∆∞∆°ng ·ª©ng
        results = []
        for idx in top_indices:
            if idx < len(self.texts) and similarities[idx] > 0:
                results.append(self.texts[idx])

        return results
