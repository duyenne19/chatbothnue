"""
BM25 Vector Store - Thu·∫≠t to√°n ranking t·ªët h∆°n TF-IDF
BM25 (Best Matching 25) t√≠nh ƒë·∫øn document length normalization
"""
import numpy as np
from typing import List
import math


class BM25VectorStore:
    """
    BM25 (Okapi BM25) - thu·∫≠t to√°n ranking vƒÉn b·∫£n
    Th∆∞·ªùng cho k·∫øt qu·∫£ t·ªët h∆°n TF-IDF cho information retrieval
    """

    def __init__(self, model_name: str = None, k1: float = 1.5, b: float = 0.75):
        """
        Args:
            model_name: Kh√¥ng d√πng, ch·ªâ ƒë·ªÉ t∆∞∆°ng th√≠ch interface
            k1: Term frequency saturation parameter (default: 1.5)
            b: Length normalization parameter (default: 0.75)
        """
        self.k1 = k1
        self.b = b
        self.texts = []
        self.tokenized_corpus = []
        self.doc_lengths = []
        self.avg_doc_length = 0
        self.doc_freqs = {}
        self.idf = {}
        self.N = 0  # S·ªë documents

    def _tokenize(self, text: str) -> List[str]:
        """Simple tokenization - split by whitespace v√† lowercase"""
        return text.lower().split()

    def _calculate_idf(self):
        """T√≠nh IDF (Inverse Document Frequency) cho m·ªói term"""
        self.idf = {}

        for term, df in self.doc_freqs.items():
            # IDF = log((N - df + 0.5) / (df + 0.5) + 1)
            # +1 ƒë·ªÉ tr√°nh log(0)
            self.idf[term] = math.log((self.N - df + 0.5) / (df + 0.5) + 1)

    def build(self, texts: List[str]):
        """
        Build BM25 index t·ª´ corpus

        Args:
            texts: Danh s√°ch documents
        """
        print("üîé ƒêang t·∫°o BM25 index (OFFLINE mode)...")

        self.texts = texts
        self.N = len(texts)

        # Tokenize t·∫•t c·∫£ documents
        self.tokenized_corpus = [self._tokenize(text) for text in texts]

        # T√≠nh document lengths
        self.doc_lengths = [len(doc) for doc in self.tokenized_corpus]
        self.avg_doc_length = sum(self.doc_lengths) / self.N if self.N > 0 else 0

        # T√≠nh document frequency cho m·ªói term
        self.doc_freqs = {}
        for doc in self.tokenized_corpus:
            unique_terms = set(doc)
            for term in unique_terms:
                self.doc_freqs[term] = self.doc_freqs.get(term, 0) + 1

        # T√≠nh IDF
        self._calculate_idf()

        print(f"‚úÖ BM25 index: {self.N} documents, "
              f"{len(self.doc_freqs)} unique terms, "
              f"avg_length={self.avg_doc_length:.1f}")

    def _score_document(self, query_terms: List[str], doc_idx: int) -> float:
        """
        T√≠nh BM25 score cho m·ªôt document

        Args:
            query_terms: Query ƒë√£ tokenize
            doc_idx: Index c·ªßa document

        Returns:
            BM25 score
        """
        score = 0.0
        doc = self.tokenized_corpus[doc_idx]
        doc_length = self.doc_lengths[doc_idx]

        # Term frequencies trong document n√†y
        term_freqs = {}
        for term in doc:
            term_freqs[term] = term_freqs.get(term, 0) + 1

        for term in query_terms:
            if term not in self.idf:
                continue  # Term kh√¥ng c√≥ trong corpus

            # TF c·ªßa term trong document
            tf = term_freqs.get(term, 0)

            # BM25 score component cho term n√†y
            # score = IDF * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (doc_len / avg_doc_len)))
            numerator = tf * (self.k1 + 1)
            denominator = tf + self.k1 * (
                1 - self.b + self.b * (doc_length / self.avg_doc_length)
            )

            score += self.idf[term] * (numerator / denominator)

        return score

    def search(self, query: str, k: int = 3) -> List[str]:
        """
        T√¨m ki·∫øm top-K documents cho query

        Args:
            query: Query string
            k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£

        Returns:
            List c·ªßa top-K documents
        """
        if self.N == 0:
            return []

        query_terms = self._tokenize(query)

        # T√≠nh score cho t·∫•t c·∫£ documents
        scores = []
        for doc_idx in range(self.N):
            score = self._score_document(query_terms, doc_idx)
            scores.append((score, doc_idx))

        # Sort theo score gi·∫£m d·∫ßn
        scores.sort(reverse=True, key=lambda x: x[0])

        # L·∫•y top-K
        top_k = scores[:k]

        # Tr·∫£ v·ªÅ documents (ch·ªâ nh·ªØng docs c√≥ score > 0)
        results = []
        for score, idx in top_k:
            if score > 0:
                results.append(self.texts[idx])

        return results

    def get_config(self) -> dict:
        """Tr·∫£ v·ªÅ config c·ªßa BM25"""
        return {
            'algorithm': 'BM25',
            'k1': self.k1,
            'b': self.b,
            'n_documents': self.N,
            'avg_doc_length': self.avg_doc_length,
            'vocab_size': len(self.doc_freqs)
        }
