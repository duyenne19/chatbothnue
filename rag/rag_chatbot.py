# rag/rag_chatbot.py
import os
from dotenv import load_dotenv
load_dotenv()

import google.generativeai as genai

from rag.config import RAGConfig
from rag.markdown_loader import MarkdownLoader
from rag.text_chunker import TextChunker
from rag.vector_store import VectorStore


class RAGChatbot:
    """
    RAG Chatbot tuy·ªÉn sinh
    - Ch·ªâ CHAT
    - KH√îNG crawl
    - Ch·ªâ d√πng d·ªØ li·ªáu Markdown ƒë√£ chu·∫©n b·ªã s·∫µn
    """

    def __init__(self, config: RAGConfig):
        self.config = config

        # ===== Load Gemini API =====
        api_key = os.environ.get("GEMINI_API_KEY")
        if not api_key:
            raise RuntimeError(
                "‚ùå Thi·∫øu GEMINI_API_KEY. "
                "H√£y c·∫•u h√¨nh trong file .env"
            )

        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(config.gemini_model)

        # ===== RAG components =====
        self.loader = MarkdownLoader(config.markdown_dir)
        self.chunker = TextChunker(
            size=config.chunk_size,
            overlap=config.overlap
        )
        self.store = VectorStore(config.embedding_model)

        self.ready = False

    # -------------------------------------------------
    def initialize(self):
        """
        Kh·ªüi t·∫°o RAG:
        - Load Markdown
        - Chunk
        - Build vector store
        """
        print("üìÑ ƒêang load d·ªØ li·ªáu Markdown...")

        documents = self.loader.load()
        if not documents:
            raise RuntimeError(
                "‚ùå Kh√¥ng t√¨m th·∫•y file content.md.\n"
                "üëâ H√£y ch·∫°y crawler tr∆∞·ªõc ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu."
            )

        chunks = []
        for doc in documents:
            doc_chunks = self.chunker.chunk(doc)
            chunks.extend(doc_chunks)

        if not chunks:
            raise RuntimeError(
                "‚ùå D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ t·∫°o chunk."
            )

        print(f"üß© T·ªïng s·ªë chunk: {len(chunks)}")
        self.store.build(chunks)

        self.ready = True
        print("ü§ñ Chatbot s·∫µn s√†ng!")

    # -------------------------------------------------
    def ask(self, question: str) -> str:
        """
        Tr·∫£ l·ªùi c√¢u h·ªèi ng∆∞·ªùi d√πng
        """
        if not self.ready:
            return "H·ªá th·ªëng ch∆∞a s·∫µn s√†ng."

        if not question.strip():
            return "Vui l√≤ng nh·∫≠p c√¢u h·ªèi."

        # ===== Retrieve =====
        contexts = self.store.search(
            question,
            self.config.top_k
        )

        if not contexts:
            return "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin n√†y trong d·ªØ li·ªáu tuy·ªÉn sinh."

        context_text = "\n\n".join(contexts)

        # ===== Prompt =====
        prompt = f"""
        B·∫°n l√† chatbot t∆∞ v·∫•n tuy·ªÉn sinh c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc S∆∞ ph·∫°m H√† N·ªôi.

        NHI·ªÜM V·ª§:
        - Tr·∫£ l·ªùi th√¢n thi·ªán, r√µ r√†ng, ƒë√∫ng vai tr√≤ t∆∞ v·∫•n tuy·ªÉn sinh
        - S·ª≠ d·ª•ng th√¥ng tin trong NG·ªÆ C·∫¢NH
        - ∆Øu ti√™n gi·∫£i th√≠ch ng√†nh h·ªçc, c∆° h·ªôi ngh·ªÅ nghi·ªáp n·∫øu c√¢u h·ªèi chung
        - Ch·ªâ tr·∫£ l·ªùi ƒëi·ªÉm chu·∫©n khi ng∆∞·ªùi d√πng h·ªèi c·ª• th·ªÉ v·ªÅ ƒëi·ªÉm/nƒÉm

        KH√îNG ƒê∆Ø·ª¢C:
        - B·ªãa th√¥ng tin
        - Tr·∫£ l·ªùi ngo√†i d·ªØ li·ªáu

        NG·ªÆ C·∫¢NH:
        {context_text}

        C√ÇU H·ªéI:
        {question}

        TR·∫¢ L·ªúI (gi·ªçng t∆∞ v·∫•n, ti·∫øng Vi·ªát, t·ª± nhi√™n):
        """

        # ===== Generate =====
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()

        except Exception as e:
            return f"‚ùå L·ªói khi sinh c√¢u tr·∫£ l·ªùi: {e}"
